{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae26c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels=pd.read_csv(\"C:/ACL/archive/hotels.csv\")\n",
    "reviews=pd.read_csv(\"C:/ACL/archive/reviews.csv\")\n",
    "users=pd.read_csv(\"C:/ACL/archive/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94154750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hotels duplicates: {hotels.duplicated().sum()}\")\n",
    "print(f\"Reviews duplicates: {reviews.duplicated().sum()}\")\n",
    "print(f\"Users duplicates: {users.duplicated().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Hotels nuls: {hotels.isnull().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Reviews nuls: {reviews.isnull().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Users nuls: {users.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.info()\n",
    "print(\"--------------------------------\")   \n",
    "hotels.info()\n",
    "print(\"--------------------------------\")\n",
    "users.info()\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d826",
   "metadata": {},
   "source": [
    "This code merges the reviews, hotels, and users datasets into one DataFrame (df) by performing left joins on the hotel_id and user_id columns to combine review, hotel, and user information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_hotel_df=reviews.merge(hotels,on='hotel_id',how='left')\n",
    "df=review_hotel_df.merge(users,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dfe36",
   "metadata": {},
   "source": [
    "After merging the hotels and users tables, the duplicate \"country\" columns were renamed to improve clarity: country_x (from hotels) became hotel_country, and country_y (from users) became user_country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78df610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"country_x\":\"hotel_country\",\"country_y\":\"user_country\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adbacd",
   "metadata": {},
   "source": [
    "The code assigns users' countries to geographic regions using a dictionary of regions and their countries. It adds a 'country_group' column with apply(), labeling unmatched countries as 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups={'North_America':['United States','Canada'],\n",
    "        'Western_Europe':['Germany','France','United Kingdom','Netherlands','Spain','Italy'],\n",
    "        'Eastern_Europe':['Russia'],\n",
    "        'East_Asia':['China','Japan','South Korea'],\n",
    "        'Southeast_Asia':['Thailand','Singapore'],\n",
    "        'Middle_East':['United Arab Emirates','Turkey'],\n",
    "        'Africa':['Egypt','Nigeria','South Africa'],\n",
    "        'Oceania':['Australia','New Zealand'],\n",
    "        'South_America':['Brazil','Argentina'],\n",
    "        'South_Asia':['India'],\n",
    "        'North_America_Mexico':['Mexico']}\n",
    "\n",
    "df[\"country_group\"]=df[\"user_country\"].apply(lambda x: next((key for key, value in groups.items() if x in value), \"Other\"))\n",
    "\n",
    "df[[\"hotel_country\",\"user_country\",\"country_group\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71282ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_scores = df.groupby(['traveller_type', 'city'])['score_overall'].mean().reset_index().sort_values(['traveller_type', 'score_overall'], ascending=[True,False])\n",
    "\n",
    "best_cities = city_scores.groupby('traveller_type').head(1)\n",
    "\n",
    "# display(city_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12429384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTION 1: Grouped Bar Chart (One subplot per traveller type) - RECOMMENDED\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "traveller_types = city_scores['traveller_type'].unique()\n",
    "\n",
    "for idx, traveller in enumerate(traveller_types):\n",
    "    # Filter data for this traveller type\n",
    "    data = city_scores[city_scores['traveller_type'] == traveller]\n",
    "    best_city = best_cities[best_cities['traveller_type'] == traveller]['city'].values[0]\n",
    "    \n",
    "    # Create colors (highlight best city in green)\n",
    "    colors = ['#2ECC71' if city == best_city else '#3498DB' for city in data['city']]\n",
    "    \n",
    "    # Plot horizontal bar chart\n",
    "    axes[idx].barh(data['city'], data['score_overall'], color=colors, edgecolor='black', linewidth=1)\n",
    "    axes[idx].set_xlabel('Average Overall Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('City', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{traveller} Travellers', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlim(0, 10)\n",
    "    axes[idx].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add score labels on bars\n",
    "    for i, (city, score) in enumerate(zip(data['city'], data['score_overall'])):\n",
    "        axes[idx].text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Add best city annotation\n",
    "    best_score = best_cities[best_cities['traveller_type'] == traveller]['score_overall'].values[0]\n",
    "    axes[idx].text(0.98, 0.98, f'ðŸ† Best: {best_city}\\nScore: {best_score:.2f}',\n",
    "                  transform=axes[idx].transAxes, fontsize=10, ha='right', va='top',\n",
    "                  bbox=dict(boxstyle='round', facecolor='#2ECC71', alpha=0.3, edgecolor='black'))\n",
    "\n",
    "plt.suptitle('Best City for Each Traveller Type Based on Overall Score', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ded78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create position for bars\n",
    "traveller_list = []\n",
    "city_list = []\n",
    "score_list = []\n",
    "color_list = []\n",
    "\n",
    "for traveller in traveller_types:\n",
    "    data = city_scores[city_scores['traveller_type'] == traveller]\n",
    "    best_city = best_cities[best_cities['traveller_type'] == traveller]['city'].values[0]\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        traveller_list.append(traveller)\n",
    "        city_list.append(row['city'])\n",
    "        score_list.append(row['score_overall'])\n",
    "        color_list.append('#2ECC71' if row['city'] == best_city else '#95A5A6')\n",
    "\n",
    "# Create grouped bar chart\n",
    "x_labels = [f\"{t}\\n{c}\" for t, c in zip(traveller_list, city_list)]\n",
    "x_pos = range(len(x_labels))\n",
    "\n",
    "plt.bar(x_pos, score_list, color=color_list, edgecolor='black', linewidth=1)\n",
    "plt.xlabel('Traveller Type - City', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Average Overall Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Overall Scores by Traveller Type and City\\n(Green = Best City for Each Traveller Type)', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(x_pos, x_labels, rotation=45, ha='right', fontsize=8)\n",
    "plt.ylim(0, 10)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Define colors for each traveller type\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "# Create bar chart\n",
    "bars = plt.bar(best_cities['traveller_type'], \n",
    "               best_cities['score_overall'], \n",
    "               color=colors, \n",
    "               edgecolor='black', \n",
    "               linewidth=1.5, \n",
    "               alpha=0.85,\n",
    "               width=0.6)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Traveller Type', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Average Overall Score', fontsize=13, fontweight='bold')\n",
    "plt.title('Best City Recommendation for Each Traveller Type', \n",
    "          fontsize=15, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 10)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add city names and scores on top of each bar\n",
    "for i, (traveller, city, score) in enumerate(zip(best_cities['traveller_type'], \n",
    "                                                   best_cities['city'], \n",
    "                                                   best_cities['score_overall'])):\n",
    "    plt.text(i, score + 0.15, f'ðŸ† {city}', \n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    plt.text(i, score - 0.4, f'{score:.2f}', \n",
    "             ha='center', va='top', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š BEST CITY RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "for _, row in best_cities.iterrows():\n",
    "    print(f\"{row['traveller_type']:15} â†’ {row['city']:20} (Score: {row['score_overall']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['traveller_type'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['city'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['user_gender'], drop_first=True)\n",
    "\n",
    "age_order = {\n",
    "    '18-24': 1,\n",
    "    '25-34': 2,\n",
    "    '35-44': 3,\n",
    "    '45-54': 4,\n",
    "    '55+': 5\n",
    "}\n",
    "\n",
    "df['age'] = df['age_group'].map(age_order)\n",
    "df.drop(columns=['age_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import final\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    'review_id',         \n",
    "    'user_id',           \n",
    "    'hotel_id',          \n",
    "    'review_date',      \n",
    "    'join_date',          \n",
    "    'user_country',     \n",
    "    'review_text',       \n",
    "    'hotel_name',        \n",
    "    'hotel_country',      \n",
    "    'lat',                \n",
    "    'lon'  \n",
    "]\n",
    "final_df=df.drop(columns=columns_to_drop)\n",
    "\n",
    "# final_df.to_csv('final_dataset.csv', index=False)   \n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff055e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()\n",
    "final_df.rename(columns={\"age_encoded\":\"age\",\"ci\":\"user_country\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1cabc",
   "metadata": {},
   "source": [
    "final_df is the cleaned dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722947b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['score_overall','score_cleanliness','score_comfort','score_facilities','score_location','score_staff','score_value_for_money','star_rating','cleanliness_base','comfort_base','facilities_base','location_base','staff_base','value_for_money_base','traveller_type_Couple','traveller_type_Family','traveller_type_Solo','city_Bangkok','city_Barcelona','city_Berlin','city_Buenos Aires','city_Cairo','city_Cape Town','city_Dubai','city_Istanbul','city_Lagos','city_London','city_Mexico City','city_Moscow','city_Mumbai','city_New York','city_Paris','city_Rio de Janeiro','city_Rome','city_Seoul','city_Shanghai','city_Singapore','city_Sydney','city_Tokyo','city_Toronto','city_Wellington','user_gender_Male','user_gender_Other','age' ]] \n",
    "y = final_df['country_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind='bar', title='Country Group Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65466a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393075aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global explanation\n",
    "explainer = shap.LinearExplainer(log_model, X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "\n",
    "\n",
    "shap_values = np.array(shap_values, dtype=np.float64)\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=X_test.shape[1])\n",
    "shap.summary_plot(shap_values, X_test, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.initjs()\n",
    "\n",
    "# # Use only a sample of X_train to make SHAP faster\n",
    "# X_train_sample = X_train.sample(300, random_state=42)\n",
    "\n",
    "# # Initialize SHAP LinearExplainer for Logistic Regression\n",
    "# explainer = shap.LinearExplainer(log_model, X_train_sample)\n",
    "\n",
    "# # Compute SHAP values\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# # Handle cases where shap_values is a list (multi-class models)\n",
    "# if isinstance(shap_values, list):\n",
    "#     shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "\n",
    "# # Convert to numpy array safely\n",
    "# shap_values = np.array(shap_values, dtype=np.float64)\n",
    "\n",
    "# # Pick one test example (e.g., index 5)\n",
    "# sample_idx = 5\n",
    "\n",
    "# # Select that row\n",
    "# X_sample = X_test.iloc[[sample_idx]]\n",
    "\n",
    "# # Compute SHAP values for this instance\n",
    "# shap_values_sample = explainer.shap_values(X_sample)\n",
    "\n",
    "# # Handle multi-class\n",
    "# if isinstance(shap_values_sample, list):\n",
    "#     shap_values_sample = shap_values_sample[1] if len(shap_values_sample) > 1 else shap_values_sample[0]\n",
    "\n",
    "# # Local force plot for one prediction\n",
    "# shap.force_plot(\n",
    "#     explainer.expected_value, \n",
    "#     shap_values_sample, \n",
    "#     X_sample\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088af0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61804e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent random state\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "# ---- Create LIME Explainer ----\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=log_model.classes_.astype(str),\n",
    "    mode='classification',\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# ---- Pick one instance ----\n",
    "sample_idx = 39\n",
    "sample = X_test.iloc[sample_idx]\n",
    "\n",
    "# Get model prediction for this instance\n",
    "pred_label = log_model.predict(sample.values.reshape(1, -1))[0]      # e.g. \"Western_Europe\"\n",
    "pred_class_idx = np.where(log_model.classes_ == pred_label)[0][0]    # convert to numeric index\n",
    "pred_class_name = log_model.classes_[pred_class_idx]\n",
    "\n",
    "print(f\"Predicted class: {pred_class_name}\")\n",
    "\n",
    "# ---- Explain ONLY the predicted class ----\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=sample,\n",
    "    predict_fn=log_model.predict_proba, \n",
    "    num_features=10,\n",
    "    labels=[pred_class_idx]   # âœ… use numeric index\n",
    ")\n",
    "\n",
    "# ---- Visualize ----\n",
    "exp.show_in_notebook(show_table=True, labels=[pred_class_idx])\n",
    "\n",
    "# ---- Text summary ----\n",
    "print(f\"\\nLIME Explanation for predicted class '{pred_class_name}':\")\n",
    "for feature, weight in exp.as_list(label=pred_class_idx):\n",
    "    print(f\"{feature}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ec843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# One-hot encode for NN output layer\n",
    "y_categorical = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_encoded shape:\", y_encoded.shape)\n",
    "print(\"y_categorical shape:\", y_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # number of country groups\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d83e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model(no change)\n",
    "# num_features = X_train_scaled.shape[1]\n",
    "# num_classes = y_train.shape[1]  \n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(num_features,)),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    epochs=50, batch_size=32,\n",
    "                    validation_split=0.2, verbose=1)\n",
    "\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"=== Neural Network Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test_scaled[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c528f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prediction function that outputs probabilities\n",
    "def predict_fn(data):\n",
    "    return model.predict(data, verbose=0)\n",
    "\n",
    "# Initialize SHAP KernelExplainer\n",
    "background = shap.sample(X_train_scaled, 100, random_state=42)\n",
    "explainer = shap.KernelExplainer(predict_fn, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abe4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values for a smaller batch\n",
    "shap_values = explainer.shap_values(background[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SHAP summary plot for global feature importance\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_sample[:100],\n",
    "    feature_names=X.columns,\n",
    "    plot_type=\"bar\",\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.title(\"Global Feature Importance (SHAP Summary)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e193168",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_sample[:100],\n",
    "    feature_names=X.columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
