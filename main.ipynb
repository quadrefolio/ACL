{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326109c9",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f10b1b",
   "metadata": {},
   "source": [
    "# Python Libraries Description\n",
    "\n",
    "## Overview\n",
    "This markdown describes Python libraries commonly used in Jupyter Notebooks for data analysis, visualization, and machine learning.\n",
    "\n",
    "## Library Descriptions\n",
    "- **numpy**: Handles numerical computations with arrays and matrices.\n",
    "- **pandas**: Manages and analyzes data using DataFrames.\n",
    "- **matplotlib.pyplot**: Generates plots and visualizations.\n",
    "- **seaborn**: Creates enhanced statistical visualizations.\n",
    "- **tensorflow**: Supports building and training machine learning models.\n",
    "- **tensorflow**: A comprehensive platform for building and training machine learning models.\n",
    "    - **tensorflow.keras**: A high-level API within TensorFlow for building and training deep learning models (e.g., `Sequential`, `Dense`, `Dropout`).\n",
    "- **scikit-learn (sklearn)**: A powerful and widely used library for classical machine learning. It includes modules for:\n",
    "    - **Preprocessing**: (e.g., `LabelEncoder`, `StandardScaler`)\n",
    "    - **Model Selection**: (e.g., `train_test_split`)\n",
    "    - **Models**: (e.g., `LogisticRegression`)\n",
    "    - **Metrics**: (e.g., `accuracy_score`, `classification_report`)\n",
    "- **lime**: Stands for Local Interpretable Model-agnostic Explanations. It's a library used to explain the predictions of any machine learning model.\n",
    "- **shap**: (SHapley Additive exPlanations) A library for explaining the output of machine learning models, providing insights into feature importance and prediction logic.\n",
    "\n",
    "## Purpose\n",
    "These libraries enable efficient data processing, visualization, and machine learning model development in Jupyter Notebooks, using standard aliases for concise coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae26c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lime import lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcc31d",
   "metadata": {},
   "source": [
    "# Loading and Preparing Data in Jupyter Notebook\n",
    "\n",
    "## Overview\n",
    "This Python code loads three CSV files into pandas DataFrames and then renames specific columns to prevent naming conflicts, preparing the data for analysis in a Jupyter Notebook.\n",
    "\n",
    "## Code Description\n",
    "- **`hotels = pd.read_csv(...)`**: Loads hotel data from a CSV file into a DataFrame named `hotels`.\n",
    "- **`reviews = pd.read_csv(...)`**: Loads review data from a CSV file into a DataFrame named `reviews`.\n",
    "- **`users = pd.read_csv(...)`**: Loads user data from a CSV file into a DataFrame named `users`.\n",
    "- **`hotels = hotels.rename(...)`**: Renames the `country` column in the `hotels` DataFrame to `hotel_country`.\n",
    "- **`users = users.rename(...)`**: Renames the `country` column in the `users` DataFrame to `user_country`.\n",
    "\n",
    "## Purpose\n",
    "This code imports datasets into pandas DataFrames. It also performs initial data cleaning by **renaming the 'country' columns** in the `hotels` and `users` tables. This is a crucial step to avoid ambiguity and prevent column name collisions before merging these DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels=pd.read_csv(\"/Users/macbookpro/Desktop/ACL/archive/hotels.csv\")\n",
    "reviews=pd.read_csv(\"/Users/macbookpro/Desktop/ACL/archive/reviews.csv\")\n",
    "users=pd.read_csv(\"/Users/macbookpro/Desktop/ACL/archive/users.csv\")\n",
    "hotels = hotels.rename(columns={'country': 'hotel_country'})\n",
    "users = users.rename(columns={'country': 'user_country'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e2c94",
   "metadata": {},
   "source": [
    "### üîç Data Quality Check\n",
    "\n",
    "This cell checks for duplicates and missing values in the **Hotels**, **Reviews**, and **Users** datasets using `duplicated()` and `isnull().sum()`.  \n",
    "It was found that there are **no duplicate records** and **no missing values** in any of the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94154750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hotels duplicates: {hotels.duplicated().sum()}\")\n",
    "print(f\"Reviews duplicates: {reviews.duplicated().sum()}\")\n",
    "print(f\"Users duplicates: {users.duplicated().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Hotels nuls: {hotels.isnull().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Reviews nuls: {reviews.isnull().sum()}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Users nuls: {users.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb841f9",
   "metadata": {},
   "source": [
    "### üßæ Dataset Overview\n",
    "\n",
    "This cell displays the structure and summary information of the **Reviews**, **Hotels**, and **Users** datasets using `info()`.  \n",
    "It shows the number of entries, column names, data types, and confirms that there are **no missing values** in any dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.info()\n",
    "print(\"--------------------------------\")   \n",
    "hotels.info()\n",
    "print(\"--------------------------------\")\n",
    "users.info()\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f954b55",
   "metadata": {},
   "source": [
    "# Merging DataFrames\n",
    "\n",
    "## Overview\n",
    "Merges pandas DataFrames (`reviews`, `hotels`, `users`) for analysis in Jupyter Notebook.\n",
    "\n",
    "## Description\n",
    "- **`review_hotel_df = reviews.merge(hotels, on='hotel_id', how='left')`**: Merges `reviews` with `hotels` on `hotel_id` using left join.\n",
    "- **`df = review_hotel_df.merge(users, on='user_id', how='left')`**: Merges `review_hotel_df` with `users` on `user_id` using left join.\n",
    "\n",
    "## Purpose\n",
    "Combines review, hotel, and user data into one DataFrame for integrated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_hotel_df=reviews.merge(hotels,on='hotel_id',how='left')\n",
    "df=review_hotel_df.merge(users,on='user_id',how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dfe36",
   "metadata": {},
   "source": [
    "## Data Integrity Check: Verifying Row Count and Nulls in Key Columns (Features about the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18607823",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total rows in df (should be ~50,000): {len(df)}\")\n",
    "print(\"\\nNull values *after* merge:\")\n",
    "print(df[['user_gender', 'age_group', 'traveller_type']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adbacd",
   "metadata": {},
   "source": [
    "# Country Grouping in DataFrame\n",
    "\n",
    "## Overview\n",
    "Assigns country groups to hotels based on their country and displays selected columns.\n",
    "\n",
    "## Description\n",
    "- **`groups = {...}`**: Defines a dictionary mapping regions to lists of countries (e.g., North_America: United States, Canada).\n",
    "- **`df[\"country_group\"] = df[\"hotel_country\"].apply(...)`**: Creates a `country_group` column by mapping `hotel_country` to a region from `groups`, defaulting to \"Other\" if not found.\n",
    "- **`df[[\"hotel_country\",\"user_country\",\"country_group\"]]`**: Selects `hotel_country`, `user_country`, and `country_group` columns for display.\n",
    "\n",
    "## Purpose\n",
    "Categorizes hotels by geographic region and shows relevant country data to fill country_group column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups={'North_America':['United States','Canada'],\n",
    "        'Western_Europe':['Germany','France','United Kingdom','Netherlands','Spain','Italy'],\n",
    "        'Eastern_Europe':['Russia'],\n",
    "        'East_Asia':['China','Japan','South Korea'],\n",
    "        'Southeast_Asia':['Thailand','Singapore'],\n",
    "        'Middle_East':['United Arab Emirates','Turkey'],\n",
    "        'Africa':['Egypt','Nigeria','South Africa'],\n",
    "        'Oceania':['Australia','New Zealand'],\n",
    "        'South_America':['Brazil','Argentina'],\n",
    "        'South_Asia':['India'],\n",
    "        'North_America_Mexico':['Mexico']}\n",
    "\n",
    "df[\"country_group\"]=df[\"hotel_country\"].apply(lambda x: next((key for key, value in groups.items() if x in value), \"Other\"))\n",
    "\n",
    "df[[\"hotel_country\",\"user_country\",\"country_group\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbdf130",
   "metadata": {},
   "source": [
    "# Data-Engineering Question 1 \n",
    "\n",
    "## Overview\n",
    "Calculates the best city for each traveller type based on reviews.\n",
    "\n",
    "## Description\n",
    "- **`city_scores = df.groupby(['traveller_type', 'city'])['score_overall'].mean().reset_index().sort_values(...)`**: Groups data by `traveller_type` and `city`, computes mean `score_overall`, resets index, and sorts by `traveller_type` (ascending) and `score_overall` (descending).\n",
    "- **`best_cities = city_scores.groupby('traveller_type').head(1)`**: Selects the top city (highest score) for each `traveller_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71282ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_scores = df.groupby(['traveller_type', 'city'])['score_overall'].mean().reset_index().sort_values(['traveller_type', 'score_overall'], ascending=[True,False])\n",
    "\n",
    "best_cities = city_scores.groupby('traveller_type').head(1)\n",
    "\n",
    "# display(city_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301eaf6",
   "metadata": {},
   "source": [
    "# The Plot of question 1\n",
    " ### üìä Best City per Traveller Type\n",
    "\n",
    "This bar chart compares the **average overall score** for different traveller types, highlighting the **best-rated city** for each group.  \n",
    "Each bar represents a traveller type, labeled with the city that received the highest score and its exact value.  \n",
    "The plot shows how preferences differ among traveller types based on their overall ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "bars = plt.bar(best_cities['traveller_type'], \n",
    "               best_cities['score_overall'], \n",
    "               color=colors, \n",
    "               edgecolor='black', \n",
    "               linewidth=1.5, \n",
    "               alpha=0.85,\n",
    "               width=0.6)\n",
    "\n",
    "plt.xlabel('Traveller Type', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Average Overall Score', fontsize=13, fontweight='bold')\n",
    "plt.title('Best City Recommendation for Each Traveller Type', \n",
    "          fontsize=15, fontweight='bold', pad=20)\n",
    "plt.ylim(0, 10)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add city names and scores on top of each bar (replace üèÜ with text)\n",
    "for i, (traveller, city, score) in enumerate(zip(best_cities['traveller_type'], \n",
    "                                                   best_cities['city'], \n",
    "                                                   best_cities['score_overall'])):\n",
    "    plt.text(i, score + 0.15, f'Best: {city}', \n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    plt.text(i, score - 0.4, f'{score:.2f}', \n",
    "             ha='center', va='top', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "# plt.xticks(rotation=0, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67054ee8",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "### üåç Top Countries by Value-for-Money Score\n",
    "\n",
    "This code calculates the **average value-for-money score** for each country within every **age group**.  \n",
    "It then sorts the results and extracts the **top 3 countries** per age group with the highest average scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2827322",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_countries=df.groupby([\"age_group\",\"user_country\"])[\"score_value_for_money\"].mean().reset_index()\n",
    "top_3=top_countries.sort_values([\"age_group\",\"score_value_for_money\"],ascending=[True,False]).groupby(\"age_group\").head(3)\n",
    "print(top_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443e508",
   "metadata": {},
   "source": [
    "## Plot: Value-for-Money Analysis\n",
    "\n",
    "### üí∞ Top 3 Countries: Value Score by Age Group\n",
    "\n",
    "This grouped bar chart visualizes the **average \"value-for-money\" score** across the **top 3 countries**. The data is further segmented by **age group**, which is represented by different colored bars (the `hue`).\n",
    "\n",
    "Each cluster of bars represents a single country, allowing for a direct comparison of how different age demographics rate the \"value-for-money\" in that location. The y-axis shows the average score, making it easy to see which country and age group combination has the highest perceived value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f243243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=top_3, \n",
    "    x='user_country', \n",
    "    y='score_value_for_money', \n",
    "    hue='age_group', \n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "plt.title('Top 3 Countries with Best Value-for-Money Score per Age Group', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Average Value-for-Money Score')\n",
    "\n",
    "plt.legend(title='Age Group')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3c640",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1048a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('city')[['country_group']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d1a4f",
   "metadata": {},
   "source": [
    "## Encoding the user country , gender , traveller type and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['traveller_type'], drop_first=True)\n",
    "# df = pd.get_dummies(df, columns=['user_country'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['user_gender'], drop_first=True)\n",
    "\n",
    "age_order = {\n",
    "    '18-24': 1,\n",
    "    '25-34': 2,\n",
    "    '35-44': 3,\n",
    "    '45-54': 4,\n",
    "    '55+': 5\n",
    "}\n",
    "\n",
    "df['age'] = df['age_group'].map(age_order)\n",
    "df.drop(columns=['age_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d5742",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06772d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'score_cleanliness', 'score_facilities', 'score_staff',\n",
    "    'star_rating', 'comfort_base', 'location_base',\n",
    "    'value_for_money_base', 'age'\n",
    "\n",
    "]\n",
    "\n",
    "corr = df[cols].corr()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap (Simplified)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_corr = corr[(corr > 0) | (corr <= -0.5)]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(strong_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Strong Correlations (>|0|)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639cf7b",
   "metadata": {},
   "source": [
    "## Feature Engineering: Score vs. Baseline\n",
    "\n",
    "### üìà Creating \"Difference\" Features\n",
    "\n",
    "This code block creates seven new \"difference\" (`diff_`) columns.\n",
    "\n",
    "These features are calculated by subtracting a \"base\" value from the actual \"score\" for categories like cleanliness, comfort, and staff. This measures how much a hotel **over-performs or under-performs** compared to its baseline.\n",
    "\n",
    "It also calculates the difference between the `score_overall` and the `star_rating`, which can show if a hotel is rated higher or lower than its official star category would suggest.\n",
    "\n",
    "Finally, the code confirms the creation and prints the `head()` of these new columns to show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7169c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['diff_cleanliness'] = df['score_cleanliness'] - df['cleanliness_base']\n",
    "df['diff_comfort'] = df['score_comfort'] - df['comfort_base']\n",
    "df['diff_facilities'] = df['score_facilities'] - df['facilities_base']\n",
    "df['diff_overall_vs_star'] = df['score_overall'] - df['star_rating']\n",
    "df['diff_location'] = df['score_location'] - df['location_base']\n",
    "df['diff_staff'] = df['score_staff'] - df['staff_base']\n",
    "df['diff_value_for_money'] = df['score_value_for_money'] - df['value_for_money_base']\n",
    "\n",
    "print(\"Successfully created all 'diff' features. ‚úÖ\")\n",
    "print(\"\\nHead of the new 'diff' features:\")\n",
    "print(df[[ 'diff_cleanliness', 'diff_comfort', 'diff_facilities','diff_overall_vs_star', 'diff_location', 'diff_staff', 'diff_value_for_money']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50c3e5",
   "metadata": {},
   "source": [
    "### üßπ Feature Selection and Cleanup\n",
    "\n",
    "This cell removes unnecessary or non-numerical columns (like IDs, text, and location data) that are not needed for analysis or modeling.  \n",
    "The resulting `final_df` contains only the relevant features for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import final\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    'review_id',         \n",
    "    'user_id',           \n",
    "    'hotel_id',          \n",
    "    'review_date',      \n",
    "    'join_date',          \n",
    "    'review_text',       \n",
    "    'hotel_name',        \n",
    "    'hotel_country',   \n",
    "    'lat', \n",
    "    'score_overall',\n",
    "    'score_cleanliness',\n",
    "    'score_comfort',\n",
    "    'score_facilities',\n",
    "    'score_location',\n",
    "    'score_staff',\n",
    "    'score_value_for_money',\n",
    "    'city',\n",
    "    'star_rating',\n",
    "    'cleanliness_base',\n",
    "    'comfort_base',\n",
    "    'facilities_base',\n",
    "    'location_base',\n",
    "    'staff_base',\n",
    "    'value_for_money_base',   \n",
    "    'user_country',            \n",
    "    'lon'  \n",
    "]\n",
    "final_df=df.drop(columns=columns_to_drop)\n",
    "\n",
    "# final_df.to_csv('final_dataset.csv', index=False)   \n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da30f5",
   "metadata": {},
   "source": [
    "# Checking for null values \n",
    "\n",
    "after checking the data in the table there was no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff055e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1cabc",
   "metadata": {},
   "source": [
    "## üéØ Defining Features (X) and Target (y)\n",
    "\n",
    "This code block prepares the data for a machine learning model by separating it into two distinct variables:\n",
    "\n",
    "1.  **`X` (Features)**: This DataFrame, `X`, holds all the **independent variables** (or features) that the model will use to learn and make predictions. It is created by selecting specific columns from the `final_df`, including:\n",
    "    * The **\"difference\" features** (e.g., `diff_overall_vs_star`, `diff_cleanliness`).\n",
    "    * **One-hot encoded features** for `traveller_type` and `user_gender`.\n",
    "    * The numerical `age` feature.\n",
    "\n",
    "2.  **`y` (Target)**: This pandas Series, `y`, holds the **dependent variable** (or target) that the model will be trained to predict.\n",
    "    * In this case, the target is the `country_group` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722947b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['diff_overall_vs_star','diff_cleanliness','diff_comfort','diff_facilities','diff_location','diff_staff','diff_value_for_money','traveller_type_Couple','traveller_type_Family','traveller_type_Solo', 'user_gender_Male','user_gender_Other','age' ]] \n",
    "y = final_df['country_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8145a",
   "metadata": {},
   "source": [
    "## Plot: Target Variable Distribution\n",
    "\n",
    "### üìä Country Group Distribution\n",
    "\n",
    "This line of code visualizes the distribution of the target variable `y` (which contains the \"Country Group\" categories).\n",
    "\n",
    "It first performs a `value_counts()` to count the total number of occurrences for each unique category in `y`. Then, it immediately uses `.plot(kind='bar')` to create a **bar chart** of these counts. The `title` is set to \"Country Group Distribution\", and `plt.show()` displays the final visual.\n",
    "\n",
    "**Observation:** The plot shows an imbalanced distribution, with a **significantly larger number of samples for the \"Western Europe\" category** compared to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind='bar', title='Country Group Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba8d687",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### üî™ Splitting Data into Training and Test Sets\n",
    "\n",
    "This line of code uses the `train_test_split` function from scikit-learn to divide the dataset into two parts: a **training set** and a **test set**.\n",
    "\n",
    "* **`X, y`**: These are the complete datasets, with `X` being the features and `y` being the target variable (labels).\n",
    "* **`test_size=0.2`**: This parameter specifies that **20%** of the data should be reserved for the test set. The remaining **80%** will be used for the training set.\n",
    "* **`random_state=42`**: This acts as a seed for the random shuffling. By setting a specific number (like 42), we ensure that the split is **reproducible**‚Äîmeaning, every time this code is run, the data will be split in the exact same way.\n",
    "\n",
    "The function returns four new variables:\n",
    "1.  **`X_train`**: The 80% of features used for training the model.\n",
    "2.  **`X_test`**: The 20% of features used for testing the model.\n",
    "3.  **`y_train`**: The corresponding 80% of labels for training.\n",
    "4.  **`y_test`**: The corresponding 20% of labels for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(\n",
    "    max_iter=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65466a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393075aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global explanation\n",
    "explainer = shap.LinearExplainer(log_model, X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "\n",
    "\n",
    "shap_values = np.array(shap_values, dtype=np.float64)\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=X_test.shape[1], show=True)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088af0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61804e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent random state\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=log_model.classes_.astype(str),\n",
    "    mode='classification',\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "sample_idx = 39\n",
    "sample = X_test.iloc[sample_idx]\n",
    "\n",
    "\n",
    "pred_label = log_model.predict(sample.values.reshape(1, -1))[0]      \n",
    "pred_class_idx = np.where(log_model.classes_ == pred_label)[0][0]    \n",
    "pred_class_name = log_model.classes_[pred_class_idx]\n",
    "\n",
    "print(f\"Predicted class: {pred_class_name}\")\n",
    "\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=sample,\n",
    "    predict_fn=log_model.predict_proba, \n",
    "    num_features=10,\n",
    "    labels=[pred_class_idx]   \n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True, labels=[pred_class_idx])\n",
    "\n",
    "print(f\"\\nLIME Explanation for predicted class '{pred_class_name}':\")\n",
    "for feature, weight in exp.as_list(label=pred_class_idx):\n",
    "    print(f\"{feature}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd90aa",
   "metadata": {},
   "source": [
    "### Encoded the string labels into integers and converted them into one-hot vectors so the neural network can understand and process the target classes numerically during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ec843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# One-hot encode for NN output layer\n",
    "y_categorical = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_encoded shape:\", y_encoded.shape)\n",
    "print(\"y_categorical shape:\", y_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23ac69",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets to evaluate the model‚Äôs performance, keeping the class distribution balanced using stratified sampling. \n",
    "Stratified sampling ensures that each class maintains the same proportion in both the training and testing sets, preventing bias toward more frequent classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2902f1",
   "metadata": {},
   "source": [
    "### Scaled the feature data using StandardScaler to normalize input values. \n",
    "This standardization centers the data around zero with unit variance, helping the neural network train faster and perform better by ensuring all features contribute equally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60387e66",
   "metadata": {},
   "source": [
    "### Built a sequential neural network model consisting of multiple layers. \n",
    "It includes two hidden layers with ReLU activation for learning complex patterns, a dropout layer to reduce overfitting, and a final softmax output layer for multi-class classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d83e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model(no change)\n",
    "# num_features = X_train_scaled.shape[1]\n",
    "# num_classes = y_train.shape[1]  \n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(num_features,)),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de58a1",
   "metadata": {},
   "source": [
    "### Compiled, trained, and evaluated the neural network model. \n",
    "The model uses the Adam optimizer and categorical cross-entropy loss suitable for multi-class classification. \n",
    "It is trained on the scaled training data with a validation split to monitor performance. \n",
    "After training, predictions are made on the test set and evaluated using accuracy, precision, recall, F1-score, and a detailed classification report to assess the model‚Äôs performance across all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    epochs=50, batch_size=32,\n",
    "                    validation_split=0.2, verbose=1)\n",
    "\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"=== Neural Network Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c3e93",
   "metadata": {},
   "source": [
    "### Used SHAP to interpret the neural network‚Äôs predictions. \n",
    "A SHAP explainer was created using a sample of the training data as background. \n",
    "It computes SHAP values to measure how much each feature contributes to the model‚Äôs predictions. \n",
    "Finally, a summary plot is generated to visualize the global feature importance and understand which features have the greatest impact on the model‚Äôs decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test_scaled[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c528f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(data):\n",
    "    return model.predict(data, verbose=0)\n",
    "\n",
    "background = shap.sample(X_train_scaled, 100, random_state=42)\n",
    "explainer = shap.KernelExplainer(predict_fn, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abe4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(background[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_sample[:100],\n",
    "    feature_names=X.columns,\n",
    "    plot_type=\"bar\",\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.title(\"Global Feature Importance (SHAP Summary)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ab429",
   "metadata": {},
   "source": [
    "### Generated a local explanation using LIME.\n",
    "LIME provides an interpretable, instance-level explanation by identifying the most influential features that contributed to a specific prediction made by the neural network. This helps understand why the model predicted a certain class for a given input sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd46c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train_scaled),\n",
    "    feature_names=X.columns,\n",
    "    class_names=le.classes_,\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "\n",
    "i = 0\n",
    "sample = X_test_scaled[i].reshape(1, -1)\n",
    "\n",
    "\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test_scaled[i],\n",
    "    predict_fn=model.predict,\n",
    "    num_features=13  \n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db696622",
   "metadata": {},
   "source": [
    "### Implemented an inference function that processes raw user input, prepares it in the same format used during training, and predicts the corresponding country group using the trained neural network. \n",
    "The function handles feature encoding, scaling, and outputs both the predicted class and the model‚Äôs confidence scores for each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b952fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_country_group(raw_input):\n",
    "\n",
    "    age_group_map = {\n",
    "        \"18-25\": 1,\n",
    "        \"26-35\": 2,\n",
    "        \"36-45\": 3,\n",
    "        \"46-55\": 4,\n",
    "        \"56+\": 5\n",
    "    }\n",
    "    age_value = age_group_map.get(raw_input.get(\"age_group\"), 3)  # default: 36-45\n",
    "\n",
    "    diff_overall_vs_star = raw_input[\"score_overall\"] - raw_input[\"star_rating\"]\n",
    "    diff_cleanliness = raw_input[\"score_cleanliness\"] - raw_input[\"cleanliness_base\"]\n",
    "    diff_comfort = raw_input[\"score_comfort\"] - raw_input[\"comfort_base\"]\n",
    "    diff_facilities = raw_input[\"score_facilities\"] - raw_input[\"facilities_base\"]\n",
    "    diff_location = raw_input[\"score_location\"] - raw_input[\"location_base\"]\n",
    "    diff_staff = raw_input[\"score_staff\"] - raw_input[\"staff_base\"]\n",
    "    diff_value_for_money = raw_input[\"score_value_for_money\"] - raw_input[\"value_for_money_base\"]\n",
    "\n",
    "    model_input = {\n",
    "        \"diff_overall_vs_star\": diff_overall_vs_star,\n",
    "        \"diff_cleanliness\": diff_cleanliness,\n",
    "        \"diff_comfort\": diff_comfort,\n",
    "        \"diff_facilities\": diff_facilities,\n",
    "        \"diff_location\": diff_location,\n",
    "        \"diff_staff\": diff_staff,\n",
    "        \"diff_value_for_money\": diff_value_for_money,\n",
    "        \"traveller_type_Couple\": 1 if raw_input[\"traveller_type\"] == \"Couple\" else 0,\n",
    "        \"traveller_type_Family\": 1 if raw_input[\"traveller_type\"] == \"Family\" else 0,\n",
    "        \"traveller_type_Solo\": 1 if raw_input[\"traveller_type\"] == \"Solo\" else 0,\n",
    "        \"user_gender_Male\": 1 if raw_input[\"user_gender\"] == \"Male\" else 0,\n",
    "        \"user_gender_Other\": 1 if raw_input[\"user_gender\"] == \"Other\" else 0,\n",
    "        \"age\": age_value\n",
    "    }\n",
    "\n",
    "    feature_columns = [\n",
    "        'diff_overall_vs_star', 'diff_cleanliness', 'diff_comfort',\n",
    "        'diff_facilities', 'diff_location', 'diff_staff',\n",
    "        'diff_value_for_money', 'traveller_type_Couple',\n",
    "        'traveller_type_Family', 'traveller_type_Solo',\n",
    "        'user_gender_Male', 'user_gender_Other', 'age'\n",
    "    ]\n",
    "\n",
    "    input_df = pd.DataFrame([model_input])[feature_columns]\n",
    "    scaled_input = scaler.transform(input_df)\n",
    "\n",
    "\n",
    "    probs = model.predict(scaled_input)\n",
    "    predicted_class = np.argmax(probs, axis=1)[0]\n",
    "    predicted_group = le.inverse_transform([predicted_class])[0]\n",
    "\n",
    "    print(f\"\\nPredicted Country Group: {predicted_group}\\n\")\n",
    "    print(\"Class Probabilities:\")\n",
    "    for cls, prob in zip(le.classes_, probs[0]):\n",
    "        print(f\"  {cls}: {float(prob):.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"predicted_group\": predicted_group,\n",
    "        \"probabilities\": {cls: float(prob) for cls, prob in zip(le.classes_, probs[0])}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103737e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"age_group\": \"26-35\",\n",
    "    \"user_gender\": \"Female\",\n",
    "    \"traveller_type\": \"Solo\",\n",
    "    \"score_overall\": 8.7,\n",
    "    \"star_rating\": 5,\n",
    "    \"score_cleanliness\": 8.5,\n",
    "    \"cleanliness_base\": 9.0,\n",
    "    \"score_comfort\": 8.2,\n",
    "    \"comfort_base\": 8.5,\n",
    "    \"score_facilities\": 7.8,\n",
    "    \"facilities_base\": 8.0,\n",
    "    \"score_location\": 8.9,\n",
    "    \"location_base\": 9.3,\n",
    "    \"score_staff\": 9.1,\n",
    "    \"staff_base\": 9.0,\n",
    "    \"score_value_for_money\": 8.4,\n",
    "    \"value_for_money_base\": 8.0\n",
    "}\n",
    "\n",
    "result = predict_country_group(sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"age_group\": \"36-45\",\n",
    "    \"user_gender\": \"Male\",\n",
    "    \"traveller_type\": \"Solo\",\n",
    "\n",
    "    # Raw scores vs base values (chosen to produce the same diffs)\n",
    "    \"score_overall\": 8.8,\n",
    "    \"star_rating\": 5.0,                      # 8.8 - 5.0 = 3.8\n",
    "\n",
    "    \"score_cleanliness\": 8.0,\n",
    "    \"cleanliness_base\": 8.5,                 # diff = -0.5\n",
    "\n",
    "    \"score_comfort\": 7.6,\n",
    "    \"comfort_base\": 8.0,                     # diff = -0.4\n",
    "\n",
    "    \"score_facilities\": 7.4,\n",
    "    \"facilities_base\": 8.0,                  # diff = -0.6\n",
    "\n",
    "    \"score_location\": 8.9,\n",
    "    \"location_base\": 9.0,                    # diff = -0.1\n",
    "\n",
    "    \"score_staff\": 9.7,\n",
    "    \"staff_base\": 9.0,                       # diff = +0.7\n",
    "\n",
    "    \"score_value_for_money\": 8.3,\n",
    "    \"value_for_money_base\": 8.0              # diff = +0.3\n",
    "}\n",
    "\n",
    "\n",
    "result = predict_country_group(sample_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire_env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
